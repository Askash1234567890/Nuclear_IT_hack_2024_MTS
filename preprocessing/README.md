## Preprocessing (Предварительная обработка)

Перед тем как начать кластеризацию, все данные были очищены и подготовлены следующим образом:

1. **Регулярные выражения**: В рамках проекта использовался базовый набор регулярных выражений для очистки текста от лишних символов, чисел и прочих элементов, которые не несут смысловой нагрузки. Этот процесс был автоматизирован и задокументирован в файле `Using_LLM.ipynb`.
2. **Лемматизация**: Лемматизация применялась к каждому слову и предложению для приведения их к базовой форме. Это помогает уменьшить количество уникальных слов и улучшить качество кластеризации.
3. **Создание словаря**: В процессе лемматизации создавался словарь, который сохраняет старые и новые формы слов. Это упрощает дальнейшую обработку и проверку текстов.
4. **Векторизация с использованием SBERT**: Для того чтобы получить эмбеддинги слов и фраз, использовалась модель **SBERT (Sentence-BERT)**. Она позволяет представить текстовые данные в виде многомерных векторов, которые затем можно кластеризовать.

## YandexGPT

Для задач перефразирования текстов также рассматривалась возможность использования **YandexGPT**. Данный инструмент может быть полезен для перефразирования сложных или неоднозначных выражений, например, для замены неформальных выражений (типа "бабосики") на более подходящие ("деньги"). Однако, следует учитывать, что использование YandexGPT является платной услугой.
